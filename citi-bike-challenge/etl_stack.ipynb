{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4341fcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import zipfile\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6bc5ed8a",
   "metadata": {},
   "source": [
    "# Extract"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c60b732",
   "metadata": {},
   "source": [
    "## Station Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fd02741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Citi Bike publishes real-time system data in GBFS format.\n",
    "# gbfs_response = requests.get('http://gbfs.citibikenyc.com/gbfs/gbfs.json').json()\n",
    "# station_information_json = requests.get(gbfs_response['data']['en']['feeds'][1]['url']).json()\n",
    "\n",
    "# # Export the station information as a json file to avoid calling real-time data everytime this notebook is run.\n",
    "# # Station info reflects the latest info upon calling the station API.  \n",
    "# with open(os.path.join('data', 'station_info.json'), 'w') as f:\n",
    "#     json.dump(station_information_json['data']['stations'], f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "545bc026",
   "metadata": {},
   "source": [
    "## Trip Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a072a181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Much like extraction of the station information, the following code needs to be executed only once to extract the trip data\n",
    "# of interest. The code has been written with downloading data for multiple months and combining them into one CSV file in mind.\n",
    "base_url = \"https://s3.amazonaws.com/tripdata/\"\n",
    "df_li = []\n",
    "\n",
    "# Limit the scope of the study to June 2022.\n",
    "year = '2022'\n",
    "# Loop through the period of interest by month. For a whole year of data, specify np.arange(1,13).\n",
    "for i in np.arange(6,7):\n",
    "    if i not in [6, 7]:\n",
    "        csv_name = f'{year}{i:02d}-citibike-tripdata.csv'\n",
    "    else:\n",
    "        # The file names for June and July of 2022 are different from those for the other months due to typo.\n",
    "        csv_name = f'{year}{i:02d}-citbike-tripdata.csv'\n",
    "    \n",
    "    # The Citi Bike system data are stored as zip files.\n",
    "    zip_name = csv_name + '.zip'\n",
    "    zip_url = base_url + zip_name\n",
    "    \n",
    "    # Request the zip file and extract its content.\n",
    "    zip_response = requests.get(zip_url)\n",
    "    with open(zip_name, 'wb') as f:\n",
    "        f.write(zip_response.content)\n",
    "    with zipfile.ZipFile(zip_name, 'r') as zip:\n",
    "        zip.extractall(year)\n",
    "    \n",
    "    # Import the extract CSV file and create a DataFrame for it.\n",
    "    df = pd.read_csv(os.path.join(year, csv_name), dtype={'start_station_id': str, 'end_station_id': str})\n",
    "    # 'ride_id' can be dropped immediately as it is used to identify trips, as do the DataFrame indices.\n",
    "    df.drop(columns=['ride_id'], inplace=True)\n",
    "    \n",
    "    df_li.append(df)\n",
    "    os.remove(zip_name)\n",
    "    os.remove(os.path.join(year, csv_name))\n",
    "    \n",
    "# Concatenate all monthly data.\n",
    "df = pd.concat(df_li, axis=0, ignore_index=True)\n",
    "\n",
    "# Edited: import the additional JC (Jersey City) data for June 2022.\n",
    "# Upon close investigation of 202206-citibike-tripdata.csv, it is noted that a few trips that ended in JC are included in the\n",
    "# dataset. Because Citi Bike extends to Jersey City and Hoboken in New Jersey, the JC data, which share the same base URL with \n",
    "# the NYC data, are included for the time period investigated.\n",
    "csv_name = f'JC-{year}06-citibike-tripdata.csv'\n",
    "zip_name = csv_name + '.zip'\n",
    "zip_response = requests.get(base_url + zip_name)\n",
    "\n",
    "with open(zip_name, 'wb') as f:\n",
    "    f.write(zip_response.content)\n",
    "with zipfile.ZipFile(zip_name, 'r') as zip:\n",
    "    zip.extractall(year)\n",
    "    \n",
    "df_jc = pd.read_csv(os.path.join(year, csv_name), dtype={'start_station_id': str, 'end_station_id': str})\n",
    "df_jc.drop(columns=['ride_id'], inplace=True)\n",
    "\n",
    "os.remove(zip_name)\n",
    "os.remove(os.path.join(year, csv_name))\n",
    "\n",
    "df = pd.concat([df, df_jc], axis=0, ignore_index=True)\n",
    "df.to_csv(os.path.join(year, f'{year}06-citibike-tripdata.csv'), index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "beba74d2",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a201bcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the ridership CSV file.\n",
    "df = pd.read_csv(os.path.join('2022', '202206-citibike-tripdata.csv'), dtype={'start_station_id': str, 'end_station_id': str})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93540363",
   "metadata": {},
   "source": [
    "## Trip Duration Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e19456d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3441935 entries, 0 to 3536181\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count    Dtype         \n",
      "---  ------              --------------    -----         \n",
      " 0   started_at          3441935 non-null  datetime64[ns]\n",
      " 1   ended_at            3441935 non-null  datetime64[ns]\n",
      " 2   start_station_name  3441935 non-null  object        \n",
      " 3   start_station_id    3441935 non-null  object        \n",
      " 4   end_station_name    3439610 non-null  object        \n",
      " 5   end_station_id      3439610 non-null  object        \n",
      " 6   start_lat           3441935 non-null  float64       \n",
      " 7   start_lng           3441935 non-null  float64       \n",
      " 8   end_lat             3441654 non-null  float64       \n",
      " 9   end_lng             3441654 non-null  float64       \n",
      " 10  member_casual       3441935 non-null  object        \n",
      " 11  trip_duration       3441935 non-null  int64         \n",
      "dtypes: datetime64[ns](2), float64(4), int64(1), object(5)\n",
      "memory usage: 341.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_1 = df.copy()\n",
    "\n",
    "# Convert start time and end time to datetime objects to calculate trip duration.\n",
    "df_1['started_at'] = pd.to_datetime(df_1['started_at'])\n",
    "df_1['ended_at'] = pd.to_datetime(df_1['ended_at'])\n",
    "df_1['trip_duration'] = (df_1['ended_at'] - df_1['started_at']).dt.total_seconds().astype('int64')\n",
    "\n",
    "# The dataset is still relatively new, so it still needs to be processed to remove trips below 60 seconds in length as per\n",
    "# https://citibikenyc.com/system-data. There are trips lasting days in the dataset, which are clearly outliers, so an upper\n",
    "# limit of one day is set as well.\n",
    "df_1 = df_1[(df_1['trip_duration']>=60) & (df_1['trip_duration']<=(60*60*24))]\n",
    "\n",
    "# The type of bikes used for each trip is outside the scope of the current study, so it will be dropped.\n",
    "df_1.drop(columns=['rideable_type'], inplace=True)\n",
    "\n",
    "df_1.info(show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e4d6607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows without end station info as the study focuses on trips that start and end at bike stations.\n",
    "df_1.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ddf8b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_start = df_1.iloc[:, [0,3,2,6,7,10,11]]\n",
    "df_start = df_start.assign(start_end='start')\n",
    "df_start.rename(columns={'started_at':'time_stamp', \n",
    "                         'start_station_id':'station_id',\n",
    "                         'start_station_name':'station_name',\n",
    "                         'start_lat':'latitude',\n",
    "                         'start_lng':'longitude'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce99b5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_end = df_1.iloc[:, [1,5,4,8,9,10,11]]\n",
    "df_end = df_end.assign(start_end='end')\n",
    "df_end.rename(columns={'ended_at':'time_stamp', \n",
    "                       'end_station_id':'station_id',\n",
    "                       'end_station_name':'station_name',\n",
    "                       'end_lat':'latitude',\n",
    "                       'end_lng':'longitude'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f79a1559",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.concat([df_start, df_end], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0615f842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6879220 entries, 0 to 6879219\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count    Dtype         \n",
      "---  ------         --------------    -----         \n",
      " 0   time_stamp     6879220 non-null  datetime64[ns]\n",
      " 1   station_id     6879220 non-null  object        \n",
      " 2   station_name   6879220 non-null  object        \n",
      " 3   latitude       6879220 non-null  float64       \n",
      " 4   longitude      6879220 non-null  float64       \n",
      " 5   member_casual  6879220 non-null  object        \n",
      " 6   trip_duration  6879220 non-null  int64         \n",
      " 7   start_end      6879220 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(2), int64(1), object(4)\n",
      "memory usage: 419.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_1.info(show_counts=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7bd9a994",
   "metadata": {},
   "source": [
    "## Station Names and Ids\n",
    "To ensure accurate groupby operations downstream, each station name should be related to its id one-to-one. However, the number of unique names is greater than the number of unique ids, indicating multiple station names referring to the same id and possibly vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78f4d422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique station names: 1650\n",
      "Number of unique station ids: 1642\n"
     ]
    }
   ],
   "source": [
    "# Check the unique station names and ids.\n",
    "print(f\"Number of unique station names: {df_1['station_name'].nunique()}\")\n",
    "print(f\"Number of unique station ids: {df_1['station_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f30c9b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4488.09: 'Boerum Pl\\\\t& Pacific St', 'Boerum Pl\\t& Pacific St'\n",
      "4781.05: 'Nassau St\\\\t& Duffield St', 'Nassau St\\t& Duffield St'\n",
      "5323.06: 'Sharon St & Olive St', 'Sharon St & Olive St_new'\n",
      "5329.08: 'Murray St\\\\t& West St', 'Murray St\\t& West St'\n",
      "5382.07: 'Forsyth St\\t& Grand St', 'Forsyth St\\\\t& Grand St'\n",
      "5883.06: 'Van Dam St & Greenpoint Ave', 'Van Dam St & Review Ave'\n",
      "6300.04: 'Skillman Ave & 43 Ave', 'Skillman Ave & 32 Pl'\n",
      "6535.04: 'W 34 St &\\\\tHudson Blvd E', 'W 34 St &\\tHudson Blvd E'\n",
      "6560.14: 'W 40 St & 7 Ave', 'W 40 St & 8 Ave'\n",
      "6708.04: 'Broadway\\\\t& W 48 St', 'Broadway\\t& W 48 St'\n"
     ]
    }
   ],
   "source": [
    "# Determine the start station ids that multiple station names refer to.\n",
    "# If the station name is related to its id one-to-one, then df_1[['start_station_name', 'start_station_id']].drop_duplicates()\n",
    "# should have the same index sequence as df_1['start_station_id'].drop_duplicates(). However, that is not the case: the \n",
    "# additional station names need to be addressed.\n",
    "diff_id = df_1[['station_name', 'station_id']].drop_duplicates().index.difference(\n",
    "    df_1['station_id'].drop_duplicates().index)\n",
    "diff = df_1.loc[diff_id]['station_id'].sort_values()\n",
    "\n",
    "# Print the start station ids with their conflicting names.\n",
    "# repr() is used to prevent escape sequence interpretation.\n",
    "for i in diff:\n",
    "    print(i + ': ' + \n",
    "          ', '.join(repr(name) for name in df_1[df_1['station_id'] == i]['station_name'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c8d80ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 6 of them, it is a simple matter of replacing '\\\\t' with '\\t' (and removing '\\t' altogether in station names), and the\n",
    "# rest can be adjusted using the station information as reference.\n",
    "df_1['station_name'] = df_1['station_name'].str.replace(r'\\\\t', r'\\t', regex=True)\n",
    "df_1['station_name'] = df_1['station_name'].str.replace(r'\\t', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "121f6a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5323.06: Sharon St & Olive St\n",
      "5883.06: Van Dam St & Greenpoint Ave\n",
      "6300.04: Skillman Ave & 43 Ave\n",
      "6560.14: W 40 St & 7 Ave\n"
     ]
    }
   ],
   "source": [
    "# Import the station information and use it as a reference to resolve the remaining conflicting station names.\n",
    "station_info = pd.read_json(os.path.join('data', 'station_info.json')).loc[:, ['short_name', 'name', 'lat', 'lon']]\n",
    "station_info.rename(columns={'short_name':'station_id'}, inplace=True)\n",
    "\n",
    "# Note that the list can be generated by the same code used to determine the station ids that multiple station names refer to.\n",
    "for i in ['5323.06', '5883.06', '6300.04', '6560.14']:\n",
    "    correct_name = station_info[station_info['station_id'] == i].name.str.cat()\n",
    "    print(i + ': ' + correct_name)\n",
    "    df_1.loc[df_1['station_id'] == i, 'station_name'] = correct_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca8c3e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Ave & 12 St: 7034.08, 7034.09\n",
      "Sharon St & Olive St: 5323.05, 5323.06\n"
     ]
    }
   ],
   "source": [
    "# Determine the station names that multiple station ids refer to.\n",
    "diff_id = df_1[['station_name', 'station_id']].drop_duplicates().index.difference(\n",
    "    df_1['station_name'].drop_duplicates().index)\n",
    "diff = df_1.loc[diff_id]['station_name'].sort_values()\n",
    "\n",
    "# Print the start station names and their conflicting ids.\n",
    "for name in diff:\n",
    "    print(name + ': ' + ', '.join(i for i in df_1[df_1['station_name'] == name]['station_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e8257bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Ave & 12 St: 7034.09\n",
      "Sharon St & Olive St: 5323.06\n"
     ]
    }
   ],
   "source": [
    "# Once again, use the station information to resolve the conflicting station ids.\n",
    "for name in diff:\n",
    "    correct_id = station_info[station_info['name'] == name]['station_id'].str.cat()\n",
    "    print(name + ': ' + correct_id)\n",
    "    df_1.loc[df_1['station_name'] == name, 'station_id'] = correct_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95b72be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique station names: 1640\n",
      "Number of unique station ids: 1640\n"
     ]
    }
   ],
   "source": [
    "# Check the unique station names and ids again.\n",
    "print(f\"Number of unique station names: {df_1['station_name'].nunique()}\")\n",
    "print(f\"Number of unique station ids: {df_1['station_id'].nunique()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "79e97e5c",
   "metadata": {},
   "source": [
    "## Station Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8a64c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>312415</th>\n",
       "      <td>40.717798</td>\n",
       "      <td>-73.993161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328252</th>\n",
       "      <td>40.717798</td>\n",
       "      <td>-73.993161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360129</th>\n",
       "      <td>40.717444</td>\n",
       "      <td>-73.993426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376208</th>\n",
       "      <td>40.717684</td>\n",
       "      <td>-73.993301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397618</th>\n",
       "      <td>40.717780</td>\n",
       "      <td>-73.993254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3175873</th>\n",
       "      <td>40.717781</td>\n",
       "      <td>-73.993242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195730</th>\n",
       "      <td>40.717516</td>\n",
       "      <td>-73.993466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3302830</th>\n",
       "      <td>40.717567</td>\n",
       "      <td>-73.993388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3333817</th>\n",
       "      <td>40.717710</td>\n",
       "      <td>-73.993271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3333848</th>\n",
       "      <td>40.717422</td>\n",
       "      <td>-73.993429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>278 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          latitude  longitude\n",
       "312415   40.717798 -73.993161\n",
       "328252   40.717798 -73.993161\n",
       "360129   40.717444 -73.993426\n",
       "376208   40.717684 -73.993301\n",
       "397618   40.717780 -73.993254\n",
       "...            ...        ...\n",
       "3175873  40.717781 -73.993242\n",
       "3195730  40.717516 -73.993466\n",
       "3302830  40.717567 -73.993388\n",
       "3333817  40.717710 -73.993271\n",
       "3333848  40.717422 -73.993429\n",
       "\n",
       "[278 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2 = df_1.copy()\n",
    "\n",
    "# Inspect the starting latitude and longitude for trips started from 5382.07.\n",
    "df_2[df_2['station_id'] == '5382.07'][['latitude', 'longitude']].drop_duplicates()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3550e666",
   "metadata": {},
   "source": [
    "Multiple pairs of latitude and longitude are tied to the same station name, but they are in close proximity, indicating that they refer to the coordinates of trips made to/from the same station. In order to map the incoming and outgoing traffic from bike stations, it is easier to work with a single set of coordinates for each station. To that end, merge the `df_2` and `station_info` DataFrames. The missing station coordinates can be imputed by averaging the trip coordinates associated with each station.\n",
    "\n",
    "As proof of concept, compare the latitude and longitude of `5382.07` from the station information with the averaged trip coordinates tied to the station: they are similar down to the fifth decimal place, which implies accuracy of about 1.1 m in physical space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ed94649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>40.717798</td>\n",
       "      <td>-73.993161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            lat        lon\n",
       "1123  40.717798 -73.993161"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_info.loc[station_info['station_id'] == '5382.07'][['lat', 'lon']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98fb2f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "latitude     40.717799\n",
       "longitude   -73.993163\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2[df_2['station_id'] == '5382.07'][['latitude', 'longitude']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53a0f786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left outer merge station_info into df_2.\n",
    "stations = station_info.copy()\n",
    "stations = stations.loc[:, ['station_id', 'lat', 'lon']]\n",
    "stations.rename(columns={'lat':'station_lat', 'lon':'station_lon'}, inplace=True)\n",
    "df_2 = pd.merge(df_2, stations, on='station_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e02f7f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6879220 entries, 0 to 6879219\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count    Dtype         \n",
      "---  ------         --------------    -----         \n",
      " 0   time_stamp     6879220 non-null  datetime64[ns]\n",
      " 1   station_id     6879220 non-null  object        \n",
      " 2   station_name   6879220 non-null  object        \n",
      " 3   latitude       6879220 non-null  float64       \n",
      " 4   longitude      6879220 non-null  float64       \n",
      " 5   member_casual  6879220 non-null  object        \n",
      " 6   trip_duration  6879220 non-null  int64         \n",
      " 7   start_end      6879220 non-null  object        \n",
      " 8   station_lat    6705127 non-null  float64       \n",
      " 9   station_lon    6705127 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(4), int64(1), object(4)\n",
      "memory usage: 577.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_2.info(show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55b8f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in missing start station coordinates with the average trip start coordinates.\n",
    "df_2['station_lat'].fillna(df_2[df_2['station_lat'].isna()].groupby('station_id')['latitude'].transform('mean'), inplace=True)\n",
    "df_2['station_lon'].fillna(df_2[df_2['station_lon'].isna()].groupby('station_id')['longitude'].transform('mean'), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14c5881a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6879220 entries, 0 to 6879219\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count    Dtype         \n",
      "---  ------         --------------    -----         \n",
      " 0   time_stamp     6879220 non-null  datetime64[ns]\n",
      " 1   station_id     6879220 non-null  object        \n",
      " 2   station_name   6879220 non-null  object        \n",
      " 3   latitude       6879220 non-null  float64       \n",
      " 4   longitude      6879220 non-null  float64       \n",
      " 5   member_casual  6879220 non-null  object        \n",
      " 6   trip_duration  6879220 non-null  int64         \n",
      " 7   start_end      6879220 non-null  object        \n",
      " 8   station_lat    6879220 non-null  float64       \n",
      " 9   station_lon    6879220 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(4), int64(1), object(4)\n",
      "memory usage: 577.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_2.info(show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad1ff423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the trip coordinates as the unique station coordinates have been determined.\n",
    "df_2.drop(columns=['latitude', 'longitude'], inplace=True)\n",
    "\n",
    "# Reorganize the columns.\n",
    "df_2 = df_2.iloc[:, [0,1,2,6,7,3,4,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "225d586c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>station_id</th>\n",
       "      <th>station_name</th>\n",
       "      <th>station_lat</th>\n",
       "      <th>station_lon</th>\n",
       "      <th>member_casual</th>\n",
       "      <th>trip_duration</th>\n",
       "      <th>start_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-06-08 18:55:00</td>\n",
       "      <td>7884.04</td>\n",
       "      <td>E 149 St &amp; Park Ave</td>\n",
       "      <td>40.818154</td>\n",
       "      <td>-73.925294</td>\n",
       "      <td>member</td>\n",
       "      <td>193</td>\n",
       "      <td>start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-06-18 16:34:50</td>\n",
       "      <td>7599.02</td>\n",
       "      <td>E 115 St &amp; Madison Ave</td>\n",
       "      <td>40.798944</td>\n",
       "      <td>-73.944846</td>\n",
       "      <td>member</td>\n",
       "      <td>779</td>\n",
       "      <td>start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-06-11 17:57:00</td>\n",
       "      <td>7599.02</td>\n",
       "      <td>E 115 St &amp; Madison Ave</td>\n",
       "      <td>40.798944</td>\n",
       "      <td>-73.944846</td>\n",
       "      <td>member</td>\n",
       "      <td>633</td>\n",
       "      <td>start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-06-23 17:32:04</td>\n",
       "      <td>5569.06</td>\n",
       "      <td>W Broadway &amp; Spring St</td>\n",
       "      <td>40.724947</td>\n",
       "      <td>-74.001659</td>\n",
       "      <td>member</td>\n",
       "      <td>392</td>\n",
       "      <td>start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-06-30 16:17:43</td>\n",
       "      <td>5779.10</td>\n",
       "      <td>E 14 St &amp; 1 Ave</td>\n",
       "      <td>40.731393</td>\n",
       "      <td>-73.982867</td>\n",
       "      <td>member</td>\n",
       "      <td>615</td>\n",
       "      <td>start</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           time_stamp station_id            station_name  station_lat  \\\n",
       "0 2022-06-08 18:55:00    7884.04     E 149 St & Park Ave    40.818154   \n",
       "1 2022-06-18 16:34:50    7599.02  E 115 St & Madison Ave    40.798944   \n",
       "2 2022-06-11 17:57:00    7599.02  E 115 St & Madison Ave    40.798944   \n",
       "3 2022-06-23 17:32:04    5569.06  W Broadway & Spring St    40.724947   \n",
       "4 2022-06-30 16:17:43    5779.10         E 14 St & 1 Ave    40.731393   \n",
       "\n",
       "   station_lon member_casual  trip_duration start_end  \n",
       "0   -73.925294        member            193     start  \n",
       "1   -73.944846        member            779     start  \n",
       "2   -73.944846        member            633     start  \n",
       "3   -74.001659        member            392     start  \n",
       "4   -73.982867        member            615     start  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf6c5740",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa2f05c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.to_csv(os.path.join('data', '202206-citibike-tripdata-cleaned.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
